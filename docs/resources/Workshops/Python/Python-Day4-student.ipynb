{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome to our last day of our python crash course. Today we will be going over some meta-cognitive skills that will be helpful as you continue to use python in your courses and research. We'll talk about how to read documentation and how to debug/troubleshoot. And then we'll put it to practice by working through a more complex plotting exercise. At the end of this session we will have time for freeform questions or to discuss other topics in python that you are interested in. As always, load the libraries by running the code block below to get started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to read documentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programming effectively actually involves a lot of reading** \n",
    "\n",
    "Primarily documentation, but also code, google results, stackexchange queries, etc. Reading the documentation of a package or library or software that you are using should probably be the first thing you do when you start using it. However, software docs pages are a much different sort of writing than we may be used to, if we're primarily used to reading journal articles, textbooks, and protocols. Knowing how and how much to read documentation is a skill that needs to be developed over time to suit your own needs. There's definitely no need to read every single page of documentation of a piece of software, especially for large libraries like `numpy` or `matplotlib`. \n",
    "\n",
    "**There are a variety of ways software can be documented** \n",
    "\n",
    "You may be handed a single script from a coleague to perform some action and that script may have **comments** in the code detailing what it does or what certain lines do. Individual functions may have what is called a **docstring**, which is a string that occurs immediately after the function definition detailing how do use that function, inputs, and outputs. Another type of documentation is a docs page or **API reference** on a website for that software, such as the page for the seaborn's [scatterplot](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) function. Many software packages also have some introductory pages like **vignettes** or **tutorials** that guide you through the basics of the software. Seaborn's [tutorial](https://seaborn.pydata.org/tutorial.html) section is a good example of this. \n",
    "\n",
    "**What documentation are we meant to read?** \n",
    "\n",
    "In general, documentation is meant to be a reference manual more than a textbook. A lot of documentation is really repetitive, because it has to exhaustively cover every single function and class available to the user. I do not recommend reading documentation like a book or in any linear way. For example, `numpy` has a variety of [mathematical functions](https://numpy.org/doc/stable/reference/routines.math.html), but you are not required to look at the doc page of each of those. It is enough to know that it exists and when you do want to use a particular one, to check the page of that specific function. The most important parts of the documentation to read first are the tutorials/user guides, which introduce the basic functionality of the software with some example code. Often times, this code is exactly what you need to get started. If you get stuck, then it's time to read the docs pages for the specific commands you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of a docs page\n",
    "\n",
    "Scientific articles typically have the same sections: Introduction, Methods, Results/Discussion. Similarly, docs pages for a function should all have some common components:\n",
    "\n",
    "* Function name and how to call it\n",
    "    * parameters in parentheses with any defaults showing\n",
    "    * positional parameters first, keyword parameters after asterisk\n",
    "* Description of function\n",
    "* Detailed parameters that can be passed to each function\n",
    "    * type of object that can be passed\n",
    "    * description of what the parameter does\n",
    "* Returns\n",
    "    * type of object(s) returned\n",
    "    * description of the object\n",
    "* Examples\n",
    "\n",
    "Let's look at the seaborn library's scatterplot [documentation](https://seaborn.pydata.org/generated/seaborn.scatterplot.html). How you read this page depends on why you're there in the first place. \n",
    "\n",
    "**Just the basics**\n",
    "\n",
    "If this is your first time encountering the function, glance at the function name and description and then go directly to the examples. This will help you understand if this function does what you think it does and give you a template to use it. \n",
    "\n",
    "**Troubleshooting**\n",
    "\n",
    "If you just encountered this error message:\n",
    "```python\n",
    "AttributeError: PathCollection.set() got an unexpected keyword argument 'axis'\n",
    "```\n",
    "Maybe you spelled a parameter wrong. Therefore, take a closer look at the function parameter values in the first line and realize \"aha, I should have used `ax` instead of `axis`\". \n",
    "\n",
    "**Exploring**\n",
    "\n",
    "If you are trying to find a specific way to customize the scatterplot, it is worth reading the entire list of parameters to see what options are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Discussion:** Read the scatterplot() function's [documentation](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) page. How does the scatterplot function give you control over the color of your points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Discussion:** What questions do you still have about the documentation page or about the scatterplot function after reading it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to read code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning to read other people's code is an important skill. Just like writing, everybody has their own coding style and when we learn to read and edit other people's code, it's mutually beneficial. Some things I've learned from reading other's code:\n",
    "\n",
    "* More efficient ways to do things\n",
    "* Common mistakes to avoid\n",
    "* New error messages and bugs\n",
    "* New problem solving strategies\n",
    "* How to write more readable/reproducible code\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a python script, reproduced from FASRC's [User Codes GitHub repo](https://github.com/fasrc/User_Codes), which is an underrated resource for anyone looking to run things on the Cannon high performance computer cluster. The script is called mc_pi.py and it calculates the value of pi via the monte-carlo method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\"\"\"\n",
    "Program: mc_pi.py\n",
    "         Monte-Carlo calculation of PI\n",
    "\"\"\"\n",
    "import random\n",
    "\n",
    "N = 100000\n",
    "\n",
    "pi = 3.1415926535897932\n",
    "\n",
    "count = 0\n",
    "for i in range(N):\n",
    "    x = random.random()\n",
    "    y = random.random()\n",
    "    z = x*x + y*y\n",
    "    if z <= 1.0:\n",
    "        count = count + 1\n",
    "\n",
    "PI = 4.0*count/N\n",
    "\n",
    "print( \"Exact value of PI: {0:7.5f}\".format(pi) )\n",
    "print( \"Estimate of PI: {0:7.5f}\".format(PI) )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Discussion:** Can you describe in words what this script is doing? What extra information do you need to understand this script?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** The above python code uses a for loop to iterate over 100,000 values. This is rather slow. Rewrite this code to use numpy's [random](https://numpy.org/doc/stable/reference/random/generated/numpy.random.random_sample.html) function and take advantage of speedy array operations. If possible, make this into a function called `mc_pi` that takes as argument N, the number of simulations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def mc_pi(N):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your code\n",
    "mc_pi(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Here is another example of someone elses's code (mine) that plots Boston's weather data. Can you annotate each chunk to describe what it does? Feel free to remove or adjust lines of the code and replay the block to see what each line does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://informatics.fas.harvard.edu/resources/Workshops/Python/data/boston_weather_data.csv')\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df['year'] = df['time'].dt.year\n",
    "df['month'] = df['time'].dt.month\n",
    "df['month_name'] = df['time'].dt.strftime('%b')\n",
    "\n",
    "df_monthly_mean = df[['year', 'month', 'month_name', 'tavg', 'tmin', 'tmax']].groupby(['month', 'month_name']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "df_long = df_monthly_mean.melt(id_vars=['month', 'month_name'], value_vars=['tmin','tmax'], var_name='temperature_type', value_name='Temperature')\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "ax = sns.barplot(data=df_long, x='month', y='Temperature', hue='temperature_type')\n",
    "ax = sns.lineplot(data=df_monthly_mean, x=df_monthly_mean[\"month\"]-1, y='tavg', marker='o', ax=ax, label='Avg Temperature')\n",
    "\n",
    "ax.set_xticks(df_monthly_mean['month'])\n",
    "ax.set_xticklabels(df_monthly_mean['month_name'])\n",
    "ax.set(xlabel=\"Month\", ylabel=\"Temperature (Celsius)\", title=\"Boston 2013-2023 Temperatures\", xticks=df_monthly_mean['month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get unstuck: troubleshooting/debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we're going to be talking about debugging code. We typically picture debugging as something that happens when you run something and there's an error message. However, there are many other reasons why we might want to take a closer look at our code and the tips here will be useful throughout the code-writing process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual debugging\n",
    "\n",
    "Here are some steps to figure out what's wrong that just involve using your own brain. This is usually my first resort as it is quick and many issues end up being about a simple typo or missing step. \n",
    "\n",
    "* Read the error message\n",
    "    * What line does it refer to?\n",
    "    * What state should the code be in at that point?\n",
    "* (Re)Read your code\n",
    "    * Explain it line by line to another person or an inanimate object\n",
    "* Add error checks\n",
    "    * Print messages to check variables and progress\n",
    "    * Peel back layers and test each layer (e.g. test each function)\n",
    "* Get another pair of eyes to look at it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the internet\n",
    "\n",
    "StackExchange-type websites are great resources for learning about the code or software you are running. These answers are what the LLMs are trained on so while it may be less convenient to read through a stackexchange answer, you will get more correct information and also more context than asking an LLM the same thing. You'll probably land on a stackexchange website if you've googled an error message or the name of your software plus some issue. Lots of people have asked lots of questions over the years and you can often find someone who has had the same problem as you.\n",
    "\n",
    "Even if you don't find the exact answer to your question, it's helpful to read about and participate in the community of people who use the same software as you. So don't be shy about posting something if you need specific advice. I've found that the Biostars community is fairly friendly.\n",
    "\n",
    "Here are some examples of questions on Biostars that I found were more helpful or interesting than what an LLM might produce:\n",
    "\n",
    "* [How To Efficiently Parse A Huge Fastq File?](https://www.biostars.org/p/10353/)\n",
    "* [Mean Length of Fasta Sequences](https://www.biostars.org/p/1758/)\n",
    "* [Why Don't We Use Binary Format [For storing DNA data]?](https://www.biostars.org/p/75178/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asking for help\n",
    "\n",
    "Often times, the quickest way to get unstuck is to ask someone for help. There are some steps you can take to make it easier for others to help you. You may know all the context of your code, but a friend or one of us at office hours is going in fresh. Here's some information that you should provide when asking for help (in approximate order of effort):\n",
    "\n",
    "1. Error message\n",
    "2. What you expected to happen\n",
    "3. What is the command you used\n",
    "4. Your environment/context\n",
    "5. A minimal reproducible example\n",
    "\n",
    "Numbers 1 through 3 are the bare minimum information, while 4 and 5 are helpful for trickier problems. Number 5 is especially important if you are asking for help in an asynchronous way, like on a forum or in an email. This allows the person helping you to run code to see the error message for themselves and test out solutions before getting back to you. \n",
    "\n",
    "If you're not familiar with **minimal reproducible examples**, it's a way to pare down your code to the smallest amount that still produces the error. Often in the process of doing this, you will find the error yourself. How to make a reproducible example (AKA **reprex**)? Here are some steps:\n",
    "\n",
    "1. Start with a fresh script\n",
    "2. Import only the libraries you need\n",
    "3. Create only the data objects/variables you need (You may need to generate data or subset your data if it's large)\n",
    "4. Write only the code that produces the error\n",
    "5. Annotate the code with comments to explain what you are trying to do\n",
    "\n",
    "If you want to then share this code (and the dummy data!) with someone else, you can either send the script to them or you can use a python package called `reprexpy`, which will format both your code and your output in a way that is easy to post in plain text online or in an email. For more information see the docs for [reprexpy](https://reprexpy.readthedocs.io/en/latest/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using LLMs to debug code\n",
    "\n",
    "Here are some ways you can use LLMs to fix code:\n",
    "\n",
    "* Use a chat-based LLM\n",
    "* Use GitHub Copilot plugin for VSCode\n",
    "\n",
    "Using LLMs to fix code is similar to asking a person for help: you want to include the context of the error as much as possible. If your LLM is integrated into your code editor, it can be as simple as highlighting the section and telling it what you expect the code to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Drosophila RNA-seq data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will be loading and working with a dataset of Drosophila RNA-seq data. This dataset is from the [paper](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1007016) \"Genomics of parallel adaptation at two timescales in Drosophila\" by Li Zhao and David J Begun PLOS Genetics 2017. In this paper, they took species of *Drosophila* and subjected them to high vs low temperature conditions to assess their climatic adaptation. \n",
    "\n",
    "We have processed the RNA-seq data from this paper and have the gene expression data of high vs low temperature conditions controlled for species. Your job is to make two plots common to RNA-seq data and discuss which plot is more informative. The first plot is an MA plot and the second a volcano plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmel_de = pd.read_csv(\"https://informatics.fas.harvard.edu/resources/Workshops/Python/data/hiVslowtemp_dmelanogaster_limmavoom_2factor.csv\", index_col=0)\n",
    "dmel_de.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MA Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Using seaborn's Axes level function, create a scatterplot of the logfold change on the y axis and the average expression on the x axis. We will adjust the look of the plot in following exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a few things we want to change about this plot:\n",
    "\n",
    "* The points should be either smaller dots and without the white outline or only the outline and in black\n",
    "* We want points with significant p values to be colored in red\n",
    "* We want a title and better axis labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** In the [documentation](https://seaborn.pydata.org/generated/seaborn.scatterplot.html) of seaborn's `scatterplot()` function, there is a parameter you can pass called `**kwargs`. This is a catch-all for key-word arguments that will be passed to the matplotlib's `scatter()` function. This is happening because seaborn's scatterplot class is an extension of matplotlib's scatter class, so it *inherits* properties of the latter. \n",
    ">\n",
    ">Go to the matplotlib scatterplot's [documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.scatter.html#) and find the properties you need to change. Pass these directly to the function and change the size/color of the dots. You can either\n",
    ">\n",
    ">* change all dots to be smaller and not have an edge color\n",
    ">* change all dots to be hollow, i.e. not have a fill color (hint: use \"none\"), with a black edge color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we're going to work on is coloring the dots based on the \"adj.P.Val\". We want the dots to be colored red if the p-value meets our threshold (p<0.01) and black if it does not. There are a few ways to do this. Let's brainstorm some approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Pair up with somebody and choose one of the above approaches to to color the points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below example, we create an array of colors, one for each observation, and pass it to the color parameter. We did it in one line by using the `apply` function and a lambda function. The `apply` function is a pandas function that takes as an input a function and applies it to each item in a series or dataframe. In this case, we applied a lambda function that returns \"red\" if the \"adj.P.Val\" is less than 0.01 and \"black\" otherwise. The way this worked was that each value of \"adj.P.Val\" column was passed to the lambda function (in place of the x) and then either \"red\" or \"black\" was returned. The result was a series the same length of the dataframe with either \"red\" or \"black\" in each row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructor will demo this version\n",
    "\n",
    "g = sns.scatterplot(data = dmel_de, x = \"AveExpr\", y = \"logFC\", color = dmel_de[\"adj.P.Val\"].apply(lambda x: \"red\" if x<0.01 else \"black\"), s=5, edgecolor=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** The next thing we'll tackle is the title, axis labels.  Work with your partner to add these to the plot. How you add them may differ depending on how you plotted the original data, i.e. with seaborn's scatterplot function or with matplotlib's scatter function.\n",
    ">\n",
    ">*Bonus* See if you can add a legend to the plot. Feel free to use any of the troubleshooting methods we've discussed so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructor demonstration\n",
    "\n",
    "g = sns.scatterplot(data = dmel_de, x = \"AveExpr\", y = \"logFC\", color = dmel_de[\"adj.P.Val\"].apply(lambda x: \"red\" if x<0.01 else \"black\"), s=5, edgecolor=None)\n",
    "g.set(title=\"MA plot of High vs Low temp\", xlabel=\"Average Expression\", ylabel=\"Log Fold Change\")\n",
    "\n",
    "# Used github copilot chat function to get the legend code\n",
    "legend_labels = ['Adj p-value <0.01', 'Adj p-value >=0.01']\n",
    "legend_colors = ['red', 'black']\n",
    "legend_handles = [plt.Line2D([0], [0], marker='o', color='w', label=label, markerfacecolor=color, markersize=5) for label, color in zip(legend_labels, legend_colors)]\n",
    "g.legend(handles=legend_handles, title=\"Significance\")\n",
    "\n",
    "# If we had used another method of creating the colors, we wouldn't have to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Now, create the volcano plot. This is a scatterplot of the -log2 adjusted p value on the y axis and the logFC on the x axis. Adjust the look of the plot to more or less match the MA plot. This time, highlight the points that have greater than 2 log fold change in red. Work with a partner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructor demonstration\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "g = ax.scatter(x = dmel_de[\"logFC\"], y = -np.log(dmel_de[\"adj.P.Val\"]), c = dmel_de[\"logFC\"].apply(lambda x: \"red\" if abs(x)>2 else \"black\"), s=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Now that you have both plots, put them together into a single figure. You will need to use matplotlib's `subplots()` function to create a figure with two axes. Then, you can pass each axis to the seaborn plotting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Discussion:** Which plot do you think is more informative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free time\n",
    "\n",
    "We've left this time open to have discussions about any questions from today or the previous workshops. Feel free to ask about anything you're curious about or want to know more about."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyworkshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
