{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python data manipulation and plotting workshop\n",
    "\n",
    "Welcome to our introductory python for bioinformatics workshop. Today our goal is to help everybody get familiar with how python handles data and how to make plots. We will first have a brief introduction to the basic data types in python, the basic data structures of lists, dictionaries, and arrays. Then we'll spend the rest of the workshop using pandas dataframes to transform data and make plots using matplotlib and seaborn.\n",
    "\n",
    "If you want to learn more about these topics, I recommend the following resources:\n",
    "\n",
    "- [The Python Tutorial](https://docs.python.org/3/tutorial/index.html)\n",
    "- [Numpy beginner's guide](https://numpy.org/doc/stable/user/absolute_beginners.html)\n",
    "- [Pandas User Guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html)\n",
    "- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python terminology\n",
    "\n",
    "Python is an object oriented language, which means everything in python is an **object**, even numbers and strings. Objects have **attributes** and **methods** (functions) and are created from **classes**. When we use the equals sign `=`, we assign objects to **variables**. The variable name then becomes a way for us to refer to that object and we can access that object's attributes and methods. \n",
    "\n",
    "Object attributes and methods are accessed by using `.` after the variable name followed by the method or attribute name. **Classes** are like blueprints for an object, so when we say something is from X class, you can automatically know it should have certain attributes and methods. For example, any object of the `str` class should have the `upper()` method that converts every character to uppercase. \n",
    "\n",
    "In this workshop, we may use both \"object\" and \"variable\" in similar ways, but they mean different things. If there is any confusion, please don't hesitate to ask for clarification. Here is a list of terminology for you to refer to. \n",
    "\n",
    "| Term | Definition |\n",
    "| --- | --- |\n",
    "| Object | The thing itself (an instance of a class) |\n",
    "| Variable | The name we give the object (a pointer to the object) |\n",
    "| Class | The blueprint for the object (defines the attributes and methods of object) |\n",
    "| Method | A function that belongs to an object |\n",
    "| Attribute | A property of an object |\n",
    "| Function | A piece of code that takes an input and gives an output/does something |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a real world analogy.\n",
    "\n",
    "My water bottle is an object. I named my waterbottle Sally. Sally is a variable because it is a name that points to the my waterbottle, the object. Sally's class is WaterBottle, which means it has attributes like \"volume\", \"color\", etc. This particular WaterBottle object has methods like \"Open\" and \"Pour\" which I have to call every time I want to drink out of it. \n",
    "\n",
    "In computer science, unlike in real life, you can't have the same variable refer to two different objects, so I can't also name my computer Sally. But, I can create another name and also have it point to the water bottle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data types\n",
    "\n",
    "When we collect data, we tend to think of them as categorical, numerical, ordinal, etc, and the specific type of data influences how we deal with them in our downstream analysis. Similarly, in computer science and in python, we need to distinguish between different data types because the functions we use to manipulate them will depend on the data we have. The basic data types are numerical, string, and boolean. In python, you can use the `type()` function to check the data type of a variable. \n",
    "\n",
    "Numerical data are data represented by a number. Numerical data can further be divided into integers `int` and floats `float`. There's also support for complex numbers, but we won't get into that for this workshop. Integers are whole numbers, while floats are numbers with decimal points. When you perform arithmetic operations on integers, they might return floats, but the reverse is not true. \n",
    "\n",
    "Below is a table of basic arithmetic operations you can perform on numerical data. You can combine an operation with an equals sign `=` to perform the operation and set the variable equal to the result in one line (eg `x += 1` adds 1 to whatever number `x` was).\n",
    "\n",
    "**Operators for numerical data**\n",
    "\n",
    "| Operator | Description |\n",
    "| --- | --- |\n",
    "| `+` | Addition |\n",
    "| `-` | Subtraction |\n",
    "| `*` | Multiplication |\n",
    "| `/` | Division |\n",
    "| `%` | Modulo (returns remainder) |\n",
    "| `**` | Exponentiation |\n",
    "| `//` | Floor division |\n",
    "|`abs()` | Absolute value |\n",
    "\n",
    "Boolean (`bool`) is a data type that can either be `True` or `False`. Booleans will come up when we start using conditional statements to compare or filter data. It's technically a subclass of `int`, where 0 is False and 1 is True. Below are some logical operators you can use to create boolean expressions.\n",
    "\n",
    "**Operators for booleans**\n",
    "\n",
    "| Operator | Description |\n",
    "| --- | --- |\n",
    "| `==` | Equal to |\n",
    "| `!=` | Not equal to |\n",
    "| `>` | Greater than |\n",
    "| `<` | Less than |\n",
    "| `>=` | Greater than or equal to |\n",
    "| `<=` | Less than or equal to |\n",
    "| `and` | Logical and |\n",
    "| `or` | Logical or |\n",
    "| `not` | Logical not |\n",
    "\n",
    "Strings are sequences of characters, and are represented by `str`. Strings are enclosed in `''` or `\"\"`. If there is a string that contains a quote, you can use the escape character `\\` to escape the quote. You can use the `+` operator to concatenate strings or the `*` operator to repeat a string. But you can't combine string with numerical data using these operators. You can use the `str()`, `int()`, and `float()` functions to convert between data types. You can do some special operations on strings, such as indexing, slicing and formatting. Indexing and slicing extract substrings from a string, while formatting allows you to insert variables into a string. String are **immutable**, meaning you can't edit a string, but you can create a new string from an existing one.\n",
    "\n",
    "**Operators for strings**\n",
    "\n",
    "| Operator | Description |\n",
    "| --- | --- |\n",
    "| `+` | Concatenation |\n",
    "| `*` | Repetition |\n",
    "| `[]` | Indexing |\n",
    "| `[:]` | Slicing |\n",
    "| `.format()` or `f\"\"` | Formatting |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to predict the output of the following lines of code to check your understanding of the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"5\"\n",
    "b = \"10\"\n",
    "c = 15\n",
    "d = \"0123456789\"\n",
    "e = True\n",
    "print(type(a))\n",
    "print(type(c))\n",
    "print(type(e))\n",
    "print(type(int(d)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"5\"\n",
    "b = \"10\"\n",
    "c = 15\n",
    "print(a + b)\n",
    "print(5 + 10)\n",
    "print(5 + 10 != c)\n",
    "print(a + b == c or 15 == c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"5\"\n",
    "b = \"10\"\n",
    "c = 15\n",
    "print(\"{} plus {} equals {}\".format(a, b, c))\n",
    "print(f\"{a} plus {b} does not equal {a + b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"0123456789\"\n",
    "print(d[9])\n",
    "print(d[:5])\n",
    "print(d[::2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of basic data structures (lists, dictionaries, and numpy arrays)\n",
    "\n",
    "In this section, we'll do a quick review of the basic data structures in python. Data structures are a way to store/organize multiple pieces of data or objects. Each data structure has different use cases and ways they represent data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Lists\n",
    "\n",
    "Lists are the most basic of data structures. They are created with `[]` and can contain any type of data. Each entry is separated by a comma. Lists are ordered and can be indexed, sliced, and concatenated just like strings. When lists are all numerical, they can also support mathematical operations like `max()` and `min()`. Lists can also be nested using another `[]` within the list. \n",
    "\n",
    "Lists are our first introduction to a **mutable** data structure, meaning you can change a list without having to create a new one. Indeed, list methods may modify your data **in place** and/or **return** a new object. If the method modifies the object in place, its return value will be `None`. Modifying in place means you don't have to assign the result of the method to a new variable, while returning a new object means you do have to assign it. For example, `list.append(x)` updates the list in place, while `list.pop()` both returns the last element and removes it from the list in place. \n",
    "\n",
    "Below are some useful operations and methods for lists. For a full list of methods, you can use `dir()` on the list or consult the [docs](https://docs.python.org/3/library/stdtypes.html#list) page. \n",
    "\n",
    "**Operations and methods for lists**\n",
    "\n",
    "| Operation/Method | Description |\n",
    "| --- | --- |\n",
    "| `+` | Concatenation |\n",
    "| `*` | Repetition |\n",
    "| `[]`, `[:]` | Indexing, slicing |\n",
    "| `.append(x)` | Add `x` to the end of the list |\n",
    "| `.extend([x, y, z])` | Add `[x, y, z]` to the end of the list |\n",
    "| `.insert(i, x)` | Add `x` at index `i` of the list |\n",
    "| `.pop(i)` | Remove and return the element at index `i`, defaults to last element if none given |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries\n",
    "\n",
    "Dictionaries store key:value pairs. Keys are typically strings or numerical identifiers, while the values can be just about anything, including other dictionaries, lists, or individual values. You can create a dictionary with `{}` or with the `dict()` function. The two ways to create a dictionary are shown below:\n",
    "\n",
    "```python\n",
    "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "my_dict = dict((\"a\", 1), (\"b\", 2), (\"c\", 3))\n",
    "```\n",
    "\n",
    "Dictionaries are unordered, so you can't index/slice them. But you can retrieve items by their key, e.g. `my_dict[\"a\"]`. Like lists, dictionaries are mutable, so you can add, remove, or update the key:value pairs in place. Other methods return \"View objects\" that allow you to see the items in the dictionary, but won't allow you to modify the dictionary. Here are some useful methods for dictionaries:\n",
    "\n",
    "**Operations and methods for dictionaries**\n",
    "\n",
    "| Operation/Method | Description |\n",
    "| --- | --- |\n",
    "| `[]` | Retrieve value by key |\n",
    "| `.keys()` | Returns a view object of the keys |\n",
    "| `.values()` | Returns a view object of the values |\n",
    "| `.items()` | Returns a view object of the key:value pairs |\n",
    "| `.update(dict)` | Updates the dictionary with the key:value pairs from another dictionary |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing vs updating data\n",
    "\n",
    "Before we move on to the next data structure, let's go over a behavior of python that can be confusing. When we create a new object like a list and assign a variable to that object, the variable is a pointer to the object and not the object itself. You can assign multiple variables to the same object, like giving multiple nicknames to the same person. This is important because when you then use that variable to modify the object, you will change the object itself and therefore all the other nicknames you gave it will refer to the updated object. Run the code block below to see a demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"my\", \"list\", \"of\", \"words\"]\n",
    "b = a\n",
    "b[0] = \"your\"\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to create a COPY of the original object when you assign a new variable to it, you can use the `copy()` method. This creates a whole new object with the same values that is independent of the original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"my\", \"list\", \"of\", \"words\"]\n",
    "b = a.copy()\n",
    "b[0] = \"your\"\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you index a list, you create a what is known as a \"shallow copy\" of the list. This means that the new list is a new object, but the elements within it can still reference the old objects. In the code block below, we have a list that contains another list `x`. When we index the outer list, we create a new list that references the list `x`. When we change that element in the new list, we also change the object that `x` references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"my\", \"nested\"]\n",
    "a = [x, \"list\", \"of\", \"words\"]\n",
    "b = a[0]\n",
    "print(b)\n",
    "b[0] = \"your\"\n",
    "print(a)\n",
    "print(b)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to understand the concept of viewing vs copying data in python and to be aware of when you are modifying the data when you may not intend to. In general, it is good practice to be explicit about whether you want to make a copy of the data when you assign a new variable. This also applies to dictionaries and array objects as we'll learn in a moment. The default behavior of these data structures when you index them is to create a view or shallow copy to save on memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Question:** Suppose I imported a large dataset into a dictionary but then only wanted to work with one of the entries. So I assign the entry I want to the variable `entry`. I then delete the original variable `data` to free up memory. Does this work? Why or why not?\n",
    "\n",
    "```python\n",
    "data = dict(a = [1, 2, 3], b = [2, 3, 4], c = [3, 4, 5])\n",
    "entry = data[\"a\"]\n",
    "del data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An aside on libraries\n",
    "\n",
    "While python can do a lot of things on its own, many of the more specialized uses for the programming language are supported by additional code libraries. Libraries are a collection of classes, objects, and functions that extend the functionality of python. In this workshop, we'll be using the `numpy`, `pandas`, `matplotlib`, and `seaborn`. Those form the basis of data analysis and plotting in python. The \"Getting started\" instructions will have already walked you through installing the libraries, but to actually use them in your code or jupyter notebook, they need to be imported. You can import an installed library with the `import` keyword, typically at the top of your script/notebook. You can also import specific functions or classes from a library using the `from` keyword. Run the code block below and notice that the libraries are imported with a shorthand name. Whenever you want to use a function or class from the library, you need to first append the shorthand to tell python you're looking for something from that library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy arrays\n",
    "\n",
    "Numpy arrays are a data structure that only contain one type of data, typically numerical, and are N-dimensional (any number of dimensions). You can create numpy arrays using the `np.array()` function or by converting other data structures to an array using `np.asarray()`. There are also many other functions that can create an array with pre-filled numbers, such as `np.zeros()` and `np.arange()`. An array is defined by its `shape`, which describes the number of elements in each dimension, also known as axes. The first axis is the number of rows, the second is the number of columns, and so on. \n",
    "\n",
    "Numpy arrays can be navigated using indexing and slicing as well as boolean masks. Mathematical operations on numpy arrays occur element-wise, meaning the operation is applied to each element in the array. There are many useful functions and methods for manipulating arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** In the code block below, we create a numpy array using the function `np.arange()`, which creates evenly spaced values with a given interval (default 1). This creates a 1D array. We then `reshape()` that 1D array to a 10 by 10 2-D array. For your exercise, use slicing to extract the numbers between 30 and 80 (not inclusive of 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.arange(0,100).reshape(10,10)\n",
    "print(my_array)\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Reshape `my_array` to any other shape and print the shape of the new array. Also print the new array itself. What do you notice about how the array is filled in when reshaped?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block below, we have used a conditional statement to filter the array for values between 30 and 80. However, what problem do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (my_array >= 30) & (my_array < 80)\n",
    "print(filt)\n",
    "print(my_array[(my_array >= 30) & (my_array < 80)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filter did not preserve the shape of the array and returned just the values divorced from their positions. If you instead want a view of the array that shows where the condition was true, you can use numpy's `np.where()` function to show the value if the condition is true and a different value if the condition is false. In the code below, we use `np.nan` as the placeholder value for where the condition is false and ask it to show the original value from `my_array` where the value is true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (my_array >= 30) & (my_array < 80)\n",
    "np.where(filt, my_array, np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform mathematical operations on arrays and they'll propagate to each element. In order for the element-wise operation to work, the two objects you're operating with either have to have the same shape or one of them has to be a scalar. Numpy also has functions that allow you to operate on the entire array, such as `np.sum()`, `np.mean()`, etc. In the code block below, we calculate the mean squared error of two dummy arrays using the formula $\\frac{1}{n}\\sum_{i=1}^{n}(predicted_i - expected_i)^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.array([1, 2, 3, 4, 5])\n",
    "expected = np.array([2, 4, 1, 5, 5])\n",
    "mse = (1/len(predicted)) * np.sum(np.square(predicted - expected))\n",
    "print(mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking down the code, you can see what is produced at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted - expected)\n",
    "print(np.square(predicted - expected))\n",
    "print(np.sum(np.square(predicted - expected)))\n",
    "print(1/len(predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** In the code block below, I have an array of assignment grades in the first array and their weights in the second array. Calculate the weighted average of the grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradeA = np.array([90, 88, 93, 85, 79, 100, 85, 92, 88, 95])\n",
    "gradeW = np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.2, 0.4])\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Now I've combined the grades and weights into a single 2D array. Do the same calculation using numpy array indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = np.array([\n",
    "    [90, 0.05],\n",
    "    [88, 0.05],\n",
    "    [93, 0.05],\n",
    "    [85, 0.05],\n",
    "    [79, 0.05],\n",
    "    [100, 0.05],\n",
    "    [85, 0.05],\n",
    "    [92, 0.05],\n",
    "    [88, 0.2],\n",
    "    [95, 0.4]\n",
    "])\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays are a powerful data structure that is oprimized for rapid mathematical operations. They form the basis of other data structures in python like the tensor in tensorflow and our next topic, the pandas dataframe. If you are working with purely numerical data, numpy arrays are the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas dataframes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often when we work with data, we have multiple variables with different data types. While numpy arrays are very flexible for numerical data, it does not work as well with a combination of numerical and categorical data or when you want to have labels for your rows and columns. Pandas is another python library that builds upon numpy and adds the ability to create DataFrames, which are 2D tables with labeled rows and columns. You can think of python DataFrames as spreadsheets from excel or dataframes from R. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by learning about the pandas `Series` object. Series are one-dimensional arrays of indexed data. It can be created from a list or a numpy array with the `pd.Series()` function. Run the code block below and observe the differences between a `Series` and a numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series = pd.Series([1, 2, 3, 4, 5])\n",
    "my_array = np.array([1, 2, 3, 4, 5])\n",
    "print(my_series)\n",
    "print(my_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that a series object has an index, which is a label for each element in the series. Numpy has an implicit index for its arrays, but Series objects have an explicit index. It's kind of like a dictionary where the keys are the indices and the values are the data. Similar to a dictionary, you can use `.values` to just get the data back. And you can also use `.index` to get the index labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indices don't have to be just numbers. They can be whatever values we want. Although duplicate index values are allowed, it is best to avoid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_english = pd.Series([90, 88, 91], index = [\"Yann\", \"Xavier\", \"Zach\"])\n",
    "grades_english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_english['Yann']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can construct dataframes from multiple Series objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_math = pd.Series([60, 55, 84], index = [\"Yann\", \"Xavier\", \"Zach\"])\n",
    "grades = pd.DataFrame({'English': grades_english, 'Math': grades_math})\n",
    "grades\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a column to an existing dataframe, you can use the `[]` operator and assign a new series, or use the `pd.concat()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades[\"History\"] = [88, 100, 93]\n",
    "grades\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how when I index into the \"history\" column, an index was added to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades[\"History\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and slicing a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrames are not just indexed by row, but also by column. You can access columns by name using the `[]` operator. If you want to access a row by the index, you can use the `.loc[]` method. Run the code blocks below and note how the indexing returns Series objects in both cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades[\"English\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.loc[\"Yann\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to select subsets of a dataframe. The rows and columns of a dataframe can be referred to either by their integer position or by their indexed name. Typically, for columns, you'll use the indexed name and can just do `[]` with the name of the column. For rows, if you want to use the integer position, you will use `.iloc[]`. If you want to use the index name, you will use `.loc[]`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, here's a handy table on the best ways to index into a dataframe:\n",
    "\n",
    "|Action|Named index|Integer Position|\n",
    "|---|---|---|\n",
    "|Select single column|`df['column_name]`|`df.iloc[:, column_position]`|\n",
    "|Select multiple columns|`df[['column_name1', 'column_name2']]`|`df.iloc[:, [column_position1, column_position2]]`|\n",
    "|Select single row|`df.loc['row_name']`|`df.iloc[row_position]`|\n",
    "|Select multiple rows|`df.loc[['row_name1', 'row_name2']]`|`df.iloc[[row_position1, row_position2]]`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with numpy arrays, you can use boolean expressions to filter dataframes. In the code block below, we demonstrate how filtering works with dataframes. You can use the `[]` operator or the `.query()` method to filter on boolean expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades[grades[\"English\"] > 90] # extract rows that meet the condition where English grade > 90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.query(\"English > 90\") # Another way to extract rows based on boolean expressions\n",
    "# Note that the column name can be used directly inside the quotes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Using a boolean expression, find out which student(s) had a higher English score than their History score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide vs long data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way our dataframe is organized can affect how we work with it. Currently, our `grades` dataframe is in what is considered a \"Wide\" format. Wide format is where levels of the same variable are spread out across the columns. In this case, the variable (implicit) of subject is split across the columns into English, Math, and History. In a \"Long\" format, subject would be one column and \"grade\" would be another column. We can convert Wide to Long format by **melting** the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we reset the index so the index gets its own column\n",
    "grades.reset_index(names=\"Name\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we pick which column(s) will uniquely identify each row/observation. In our case, it's the Name of the student. We select which columns we want to melt together. They should all be levels of the same variable. Then, we select the name of the new column that will collect all the \"value_vars\". Finally, we give a name to the values associated with those variables, aka. \"Grade\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_long = grades.reset_index(names = \"Name\").melt(id_vars = 'Name', value_vars = [\"English\", \"Math\", \"History\"], var_name = 'Subject', value_name = 'Grade')\n",
    "grades_long\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melting a dataset from Wide to Long will facilitate plotting with seaborn in the future. It also makes it easier to filter and manipulate dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting directly from dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One neat feature of pandas is that you can directly plot dataframes using the `.plot()` method. This method is a wrapper around matplotlib. In the code block below, we create a bar plot of the student's grades. Just as we will see with matplotlib, the plot function return an object we'll call ax, that we can use to further customize the plot. \n",
    "\n",
    "Ironically, the `plot()` method works better in our case with the wide data format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = grades.plot(kind = 'bar')\n",
    "ax.set_ylabel('Grade')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `plot()` on a pandas DataFrame is a quick and easy way to visualize data on a high level. For more information on the this method, you can consult the visualization section of the pandas documentation [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data into a dataframe\n",
    "\n",
    "One of the most useful features of pandas DataFrames is its ability to easily perform complex data transformations. This makes it a powerful tool for cleaning, filtering, and summarizing tabular data. Let's read some data into a DataFrame to demonstrate. This data comes from the Tidy Tuesday project, which posts a neat dataset every week. This data is from January 30, 2024 and is about all the recorded instances of groundhog day predictions. Groundhog Day is a North American tradition in which a groundhog emerges from its shadow on Feb 2 and if it sees its shadow, will go back inside and there will be 6 more weeks of winter. If it does not see its shadow, spring will come early. You can find out more about this dataset at the official TidyTuesday [github repo](https://github.com/rfordatascience/tidytuesday/tree/master/data/2024/2024-01-30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see an example of how to read csvs into pandas using the `pd.read_csv()` function. This function automatically detected a delimiter of comma and I didn't have to pass any additional arguments. Unlike numpy's `loadtxt` function, it can handle missing data and data of multiple types easily. For trickier imports, you can look at all the options on the pandas [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundhogs = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-30/groundhogs.csv')\n",
    "predictions = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-01-30/predictions.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split into 2 pieces. groundhogs has information on each groundhog, such as its id, name, and location. predictions has the record for historical predictions of each grounhog, by id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundhogs.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's always a good idea to check your dtypes!\n",
    "groundhogs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's always a good idea to check your dtypes!\n",
    "predictions.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby and summarize\n",
    "\n",
    "One of the simplest things we can do is summarize how many predictions occured in each year. We can use the `groupby()` function to combine all the data for each unique value of \"year\" and then the `size()` function on that grouped dataframe to count the size of each group. This returns a `pd.Series` object with the year as the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.groupby(\"year\").size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Using the groundhogs dataframe, display how many groundhogs vs non-groundhogs have participated. *hint* The column of interest is called \"is_groundhog\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of yearly predictions, I want to instead bin these years into decades. Let's create a new column in the predictions dataframe that is the decade of the year. \n",
    "\n",
    "In the first line below, I'm creating a new column in the predictions dataframe called \"decade\" that is the year divided by 10 and floored `//` times 10 again. So the year 1999 becomes 199 becomes 1990. Notice that creating a new column in a dataframe is as simple as assigning a value to a new key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['decade'] = predictions['year'] // 10 * 10\n",
    "predictions.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to summarize the number of predictions per decade, I use the `groupby()` method again. In this case, I grouped by \"decade\" and used the method size() to see how many observations/rows exist per decade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.groupby(\"decade\").size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can \"groupby\" multiple columns by passing a list of column names. In the code block below, I group by both \"decade\" and \"shadow\" to see how many times a shadow was seee each decade. This returns a multi-indexed pandas Series, where each combination of \"decade\" and \"shadow\" (for which there is a value) is a unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predictions.groupby([\"decade\", \"shadow\"]).size()\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to turn this Series into a DataFrame where the index values are columns, we can use the `reset_index()` method. This will turn the multi-index into columns and create a new integer index. Why would we want to do this? DataFrames are a bit easier to work with than Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.reset_index(name = \"count\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use the `unstack()` method to turn the multi-index into columns. This will automatically fill in missing values with `NaN`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.unstack()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out if there are differences between the predictions of groundhogs vs non-groundhogs. We will need to combine the groundhogs and the predictions dataframes. Merging is a way to combine two dataframes based on a common column or index. In the code block below, we've created two dataframes that share the column \"A\". The DataFrames do not share columns \"B\" and \"C\". Additionally, `df2` has one more row than `df1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],'B': ['B0', 'B1', 'B2', 'B3']})\n",
    "df2 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3', 'A4'],'C': ['C0','C1', 'C2', 'C3', 'C4']})\n",
    "print(df1)\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we merge the two dataframes using the `pd.merge()` function, we can specify that the column to merge on is \"A\" and whether to keep only rows in common (default) or to keep all rows (`how='outer'`). Note that when we do the outer merge, the missing values are filled in with `NaN`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.merge(df1, df2, on = 'A'))\n",
    "print(pd.merge(df1, df2, on = 'A', how = 'outer'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Merge the groundhogs and predictions dataframes on the 'id' column and save it to a dataframe called \"combined\". Then, use groupby to summarize the number of shadow predictions made by groundhogs vs non-groundhogs. (You'll need to groupby two columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip for the next exercise: When you are chaining multiple methods together, you can split the command across multiple lines for readability. Just enclose the entire command in parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This plots a comparison of the predictions of groundhogs vs non-groundhogs\n",
    "(combined\n",
    " .groupby([\"is_groundhog\", \"shadow\"])\n",
    " .size()\n",
    " .unstack()\n",
    " .plot(kind = \"bar\", xlabel = \"Is it a groundhog?\", ylabel = \"Number of Predictions\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Using the combined dataframe, plot the number of predictions made each year by both real and fake groundhogs as a line plot. Color the line by whether the groundhog is a groundhog or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've done some high level data manipulation and plotting with pandas. Now it's time to go back to the basics and gain a foundational understanding of how to make plots in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting basics with matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib is probably the most popular library for plotting figures in python. It is the basis of other plotting libraries, such as seaborn and the pandas dataframe plots. In this section we will demonstrate how to plot with matplotlib to illustrate the underlying principles of plotting. However, because seaborn is essentially a user-friendly wrapper around matplotlib, we'll save the exercises for the seaborn section.\n",
    "\n",
    "There are two ways to plot using matplotlib: the object-oriented interface and the pyplot interface. The pyplot interface was designed to help folks transitioning from MATLAB to python. The object-oriented interface is the more reccommended way to plot figures if you're completely new. To begin plotting, we first have to import the library.\n",
    "\n",
    "Simple plots such as scatter and line plots with one or two variables are easy to create in matplotlib. The steps to plotting are as follows:\n",
    "\n",
    "1. Create a figure and Axes object using `plt.subplots()`\n",
    "2. Use the Axes object to plot the data using one of the plot methods such as `.scatter()`, `.bar()`, etc. \n",
    "3. Customize the plot using the Axes object's `.set_...` methods\n",
    "4. Add a legend using `ax.legend()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate some data\n",
    "expected = np.linspace(0, 10, 5)\n",
    "predicted1 = expected + np.random.normal(0, 1, 5)\n",
    "predicted2 = expected + np.random.normal(0, 1, 5)\n",
    "\n",
    "# Create a subplot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot each group\n",
    "ax.scatter(x = expected, y = predicted1)\n",
    "ax.scatter(x = expected, y = predicted2)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel(\"Expected\")\n",
    "ax.set_ylabel(\"Predicted\")\n",
    "\n",
    "# Add legend\n",
    "ax.legend([\"Group 1\", \"Group 2\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I wanted to plot these points in two different graphs, I can create two Axes objects and plot the data on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "# plot each subplot\n",
    "\n",
    "ax[0].scatter(x = expected, y = predicted1)\n",
    "ax[1].scatter(x = expected, y = predicted2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking down the grammar of matplotlib\n",
    "\n",
    "There are many ways to customize a matplotlib plot, but to understand how, we first need to understand the objects returned by the `plt.subplots()` function and how the plot is constructed. The first object that `plt.subplots()` returns is a `matplotlib.figure.Figure` instance. It is a top-level container for all plot elements. This object is like the **canvas** of a painting, and holds parameters such as the size of the entire plot, the background color, how subplots are layed out, etc. The `Figure` also holds all the `Axes` which are the actual plots that are going to be drawn. The second object is a `matplotlib.axes.Axes` object. Think of this like an **artist** that *draws* on the canvas. When customizing plots, such as choosing which data to plot, how to plot it, and in what colors or shapes, you will be interacting with the `Axes` object. \n",
    "\n",
    "In the below code blocks, we break down the generation of the Figure object and the Axes object into multiple lines to show how they are related. (note that in the jupyter notebook environment, we had to repeat the previous lines per code block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the data\n",
    "N = 50\n",
    "\n",
    "df = pd.DataFrame({\"x_values\": np.random.rand(N), \\\n",
    "    \"y_values\": np.random.rand(N), \\\n",
    "    \"class\": np.random.randint(0,4, size = N), \\\n",
    "    \"size\": np.random.randint(20,300, size = N)})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just generating a figure creates a canvas, but no axes, so nothing is drawn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Figure object can add a subplot and returns an Axes object, also known as an \"Artist\". Now we have a blank canvas with a blank plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the data to the Axes object, which has methods for different types of plots, including `scatter()`. The Axes object draws the points, and then returns another object representing those points. This is an object of the class `PathCollection`. The pts (PathCollection) object has its own methods for customizing just those dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "pts = ax.scatter(x = df[\"x_values\"], y = df[\"y_values\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, we'll be creating the fig and ax objects in the same line using the `plt.subplots()` function, as demonstrated below. We can use additional parameters during the `scatter()` method to customize the plot, such as adding color or size parameters with additional data. \n",
    "\n",
    "The PathCollection object can be used to create a legend for the plot. We use `ax.legend()` and pass it the object's `legend_elements()` method to create a legend. \n",
    "\n",
    "Finally. we can then use `ax.set()` to change the labels of the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot the data\n",
    "pts = ax.scatter(x = df[\"x_values\"], y = df[\"y_values\"], c = df[\"class\"], s = df[\"size\"])\n",
    "\n",
    "# create the legend\n",
    "legend1 = ax.legend(*pts.legend_elements(), loc = \"lower left\", title = \"Classes\")\n",
    "\n",
    "# add x, y, and title labels\n",
    "ax.set(xlabel = \"X\", ylabel = \"Y\", title = \"Scatterplot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we actually have two legends to add, one for the color and one for the sizes. Unfortunately, `ax.legend()` replaces existing legends so here we are creating the first legend, using the `ax.add_artist()` method to add it to the plot, and then creating another legend to be added to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot the data\n",
    "pts = ax.scatter(x = df[\"x_values\"], y = df[\"y_values\"], c = df[\"class\"], s = df[\"size\"])\n",
    "\n",
    "# create the legend\n",
    "legend1 = ax.legend(*pts.legend_elements(), loc = \"lower left\", title = \"Classes\")\n",
    "\n",
    "### new\n",
    "# manually add the first legend (for the classes) to the plot\n",
    "ax.add_artist(legend1) \n",
    "### new\n",
    "\n",
    "### new\n",
    "# create a second legend for the sizes\n",
    "legend2 = ax.legend(*pts.legend_elements(prop = \"sizes\", alpha = 0.6), loc = \"upper right\", title = \"Sizes\") \n",
    "### new\n",
    "\n",
    "# add x, y, and title labels\n",
    "ax.set(xlabel = \"X\", ylabel = \"Y\", title = \"Scatterplot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, for every element of a plot, there is a corresponding object or parameter of an object than you use to customize it. Matplotlib can get pretty granular. The matplotlib \"Anatomy of a figure\" image and its corresponding [docs page](https://matplotlib.org/stable/gallery/showcase/anatomy.html) will be helpful to understand how to customize different parts of a plot. These labels are a mix of objects and their functions, but they should give you a good idea of what you can customize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://matplotlib.org/stable/_images/sphx_glr_anatomy_001_2_00x.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using loops to plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is relatively simple to plot two axes in one figure. Give `plt.subplots` two numbers representing the number of rows and columns you want and the Axes object it returns will beceome an array. You can then index into it to plot on each object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].text(0.5, 0.5, \"Top plot\", ha = \"center\")\n",
    "ax[1].text(0.5, 0.5, \"Bottom plot\", ha = \"center\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to plot multiple subplots, pass the number of rows and columns of subplots you want to the `plt.subplots()` function. This will return an array of axes objects which you can index into to plot on each subplot. For larger plots, it's helpful to increase the size of the canvas using the `figsize` parameter in `plt.subplots()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration of looping through axes to plot multiple subplots\n",
    "fig, ax = plt.subplots(3, 3, figsize = (10, 10))\n",
    "# This flattens the 2D array of axes into a 1D array\n",
    "# Alternatively, you can use a nested loop to plot by row and column\n",
    "ax = ax.flatten()\n",
    "for i in range(9):\n",
    "    # draw number in center of plot\n",
    "    ax[i].text(0.5, 0.5, str(i), fontsize = 18, ha = 'center')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to plot several sets of data on the same plot is to use a loop over the discrete values. In the code block below, we demonstrate plotting the separate classes of data from the `df` object in a loop. Notice that we can use the `label` parameter to assign each class its own label and that we do not have to save the PathCollection object to create the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo code block of looping through columns to plot multiple data sets on one axes\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# make a dictionary of values you want associated with each class\n",
    "classes = {\n",
    "    0: {\n",
    "        \"color\": \"red\",\n",
    "        \"label\": \"Class 0\"\n",
    "    },\n",
    "    1: {\n",
    "        \"color\": \"blue\",\n",
    "        \"label\": \"Class 1\"\n",
    "    },\n",
    "    2: {\n",
    "        \"color\": \"green\",\n",
    "        \"label\": \"Class 2\"\n",
    "    },\n",
    "    3: {\n",
    "        \"color\": \"orange\",\n",
    "        \"label\": \"Class 3\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for key in classes:\n",
    "    # filter the data to only include the current class you're plotting\n",
    "    data = df[df[\"class\"] == key]\n",
    "    # plot just that class and assign the color and label\n",
    "    ax.scatter(x = data[\"x_values\"], y = data[\"y_values\"], c = classes[key][\"color\"], label = classes[key][\"label\"])\n",
    "\n",
    "# the bbox_to_anchor argument moves the legend outside of the plot\n",
    "ax.legend(bbox_to_anchor=(1.25, 0.5))\n",
    "\n",
    "# You can continue modifying the ax outside of the loop\n",
    "ax.set(xlabel = \"X\", ylabel = \"Y\", title = \"Scatterplot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better plotting with seaborn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While matplotlib can be very powerful, it's not very user friendly and takes a lot of in depth knowledge to get a plot that is even slightly complicated. The purpose of the previous section was to introduce the conceptual underpinnings of the object oriented plotting interface. Now, we will learn how to plot with the library seaborn, which is built on top of this interface and takes care of a lot of the details for you. One of the reasons seaborn is so easy to work with is that it is built to work with pandas DataFrames whereas matplotlib existed before pandas and was built to work with numpy arrays. For the most part, we recommend using seaborn for your regular plotting needs while keeping in mind the matplotlib background if you want to tweak something super specific that may not be available in seaborn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the one-line code to plot the same scatter plot we did with matplotlib. As you can see, seaborn does a lot of the drawing of the plot for us, leaving us to just specify the names of the variables and where to plot them. Like matplotlib, seaborn's plotting functions return an object that can be used to further customize the plot.\n",
    "\n",
    "The `relplot()` function is a high level function that is designed to plot both scatter and line plots. You can specify the type using the \"kind\" parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(data = df, x = \"x_values\", y = \"y_values\", hue = \"class\", size = \"size\", kind = \"scatter\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`relplot()`, along with `distplot()` and `catplot()` are \"Figure-level\" functions which provides a unified interface to plot multiple types of \"axes-level\" plots. Figure-level functions return a `FacetGrid` object which can be used to customize the plot. You can also directly use the axes-level functions, such as `sns.scatterplot()` and they will return the familiar `matplotlib.pyplot.Axes` object. In the image below, you can see the how the axes-level functions are encompassed by each figure-level function.\n",
    "\n",
    "![](https://seaborn.pydata.org/_images/function_overview_8_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure level plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a real dataset that contains a mixture of categorial and continuous variables to illustrate seaborn's plotting capabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below demonstrates how to use a figure-level function to plot a scatter plot of the penguins dataset. Notice that we now use `hue` instead of `c` to color the points by sex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data = penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", hue = \"sex\", kind = \"scatter\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below demonstrates how to use the figure-level function `relplot()` to break up a scatterplot into three facets based on the species of penguin using the \"col\" parameter. We can then use the FacetGrid object to customize the axis labels and also to acess the Axes level objects it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.relplot(data = penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", hue = \"sex\", kind = \"scatter\", col = \"species\")\n",
    "\n",
    "# Using the FacetGrid methods to customize the figure\n",
    "g.set_axis_labels(\"Bill Length (mm)\", \"Bill Depth (mm)\")\n",
    "# A tricky/annoying way to edit the legend. \n",
    "# You have to access a private attribute rather than use a method\n",
    "g._legend.set_title(\"Sex\")\n",
    "\n",
    "# Dropping down to the matplotlib axes objects that are contained in the FacetGrid object\n",
    "g.axes[0,0].set_title(\"Adelie\")\n",
    "g.axes[0,1].set_title(\"Chinstrap\")\n",
    "g.axes[0,2].set_title(\"Gentoo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Axes level plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to compose multiple plots of different kinds, it's best to use the axes-level functions, as they are regular matplotlib objects and can be composed just like we learned previously. Just like before, we create the fig and ax objects using `plt.subplots()`, but this time we pass the axes objects as a parameter in the seaborn axes-level functions. Then, just as before with matplotlib, we use the returned ax objects to set the labels and other customizations for each subplot. \n",
    "\n",
    "This syntax is very similar to base matplotlib, but because of its native support for pandas dataframes, the code is much easier to read and write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard matplotlib opening\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 8))\n",
    "plt.tight_layout(pad = 3) # adjust the padding of the subplots and the main title\n",
    "\n",
    "# now we switch to using seaborn plotting functions\n",
    "p1 = sns.boxplot(data = penguins, x = \"species\", y = \"bill_depth_mm\", hue = \"sex\", ax = ax[0])\n",
    "p2 = sns.scatterplot(data = penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", hue = \"species\", ax = ax[1])\n",
    "\n",
    "# the below is all matplotlib code\n",
    "p1.set(xlabel = \"\", ylabel = \"Bill Depth (mm)\")\n",
    "p1.legend(title = \"Sex\")\n",
    "p2.set(xlabel = \"Bill Length (mm)\", ylabel = \"Bill Depth (mm)\")\n",
    "p2.legend(title = \"Species\")\n",
    "\n",
    "fig.suptitle(\"Penguin Measurements\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, if you're doing one type of plot, it's easiest to use the Figure level function. This is because these functions take care of placing the legend sensibly outside the plot, resizing the canvas to fit the data, and can easily facet subplots by category automatically. \n",
    "\n",
    "If you want to compose a plot with multiple different types of subplots or integrate a plot with base matplotlib objects, use the axes-level functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** Create a single violin plot comparing the body mass of the penguins by both sex and species. Customize the axis labels and legend title. You may use either `sns.violinplot()` or `sns.catplot()` to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Using catplot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Using violinplot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Exercise:** The penguins dataset has 7 variables. Utilize a Figure-level function to plot as many of them as you can at once in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jointplots and pairplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another group of figure-level functions are `jointplot()` and `pairplot()`. `jointplot()` is used to plot the relationship between two continuous variables and the distribution of each variable. `pairplot()` is used to plot the relationship between all pairs of continuous variables in a dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block below, you can see that a joint plot is a scatter plot in the middle and then a kernel density estimate plot of each variable on the sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data = penguins, x = \"bill_depth_mm\", y = \"bill_length_mm\", hue = \"species\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like other figure level functions, you can use \"kind\" to swap between different representations, in this case \"kind\" can be one of scatter, kde, hist, hex, reg, resid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data = penguins, x = \"bill_depth_mm\", y = \"bill_length_mm\", hue = \"species\", kind = \"kde\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pairplot plots a grid of scatter plots of all pairs of continuous variables. On the diagonal, it plots the distributions of each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = penguins, hue = \"species\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing plotting with matplotlib, pandas, and seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seaborn\n",
    "\n",
    "long_grades = grades.reset_index().melt(id_vars = 'index', value_vars = [\"English\", \"Math\", \"History\"], var_name = 'Subject', value_name = 'Grade')\n",
    "fig, ax = plt.subplots()\n",
    "long_bar = sns.barplot(data = long_grades, x = 'index', y = 'Grade', hue = 'Subject')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pandas\n",
    "\n",
    "ax = grades.plot(kind = 'bar')\n",
    "ax.set_ylabel('Grade')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matplotlib\n",
    "\n",
    "width = 0.3  # the width of the bars\n",
    "x = np.arange(len(grades.index))  # the label locations\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x - width, grades[\"Math\"], width, label='Math')\n",
    "ax.bar(x, grades[\"History\"], width, label='History')\n",
    "ax.bar(x + width, grades[\"English\"], width, label='English')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Students')\n",
    "ax.set_ylabel('Grades')\n",
    "ax.set_title('Grades by subject')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(grades.index)\n",
    "ax.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyworkshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
